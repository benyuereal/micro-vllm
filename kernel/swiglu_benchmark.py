#!/usr/bin/env python3
# kernel/swiglu_benchmark_qwen7b.py
"""
SwiGLU Qwen-7B ä¸“é¡¹æ€§èƒ½åŸºå‡†æµ‹è¯•
- ç»´åº¦: H=4096, I=11008 (Qwen-7B æ ‡å‡†)
- è¦†ç›– Batch Size: 1~128 (æ¨¡æ‹Ÿ 2048 seq_len åœºæ™¯)
- å¯¹æ¯”: PyTorch åŸç”Ÿ vs åˆ†ç¦»æ¶æ„ä¼˜åŒ–ç‰ˆ
"""
import torch
import torch.nn.functional as F
import time
import sys
import os
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from swiglu import fused_swiglu


class Qwen7BSwiGLUBenchmark:
    def __init__(self, device='cuda', dtype=torch.float16):
        self.device = device
        self.dtype = dtype
        # Qwen-7B æ ‡å‡†ç»´åº¦
        self.H = 4096      # hidden_size
        self.I = 11008     # intermediate_size (4096 * 2.6875)
        self.seq_len = 2048  # æ ‡å‡†åºåˆ—é•¿åº¦
        
        print(f"ğŸš€ Qwen-7B SwiGLU Benchmark")
        print(f"   Device: {torch.cuda.get_device_name(0)}")
        print(f"   Dtype: {dtype}")
        print(f"   Config: H={self.H}, I={self.I}, SeqLen={self.seq_len}")
        print("=" * 80)
    
    def _generate_weights(self):
        """ç”Ÿæˆç¬¦åˆçœŸå®åˆ†å¸ƒçš„ Qwen-7B æƒé‡"""
        # Qwen ä½¿ç”¨ std=0.02 çš„åˆå§‹åŒ–
        scale = 0.02
        
        gate_w = torch.randn((self.I, self.H), device=self.device, dtype=self.dtype) * scale
        up_w = torch.randn((self.I, self.H), device=self.device, dtype=self.dtype) * scale
        down_w = torch.randn((self.H, self.I), device=self.device, dtype=self.dtype) * scale
        
        return gate_w, up_w, down_w
    
    def _generate_input(self, batch_size):
        """ç”Ÿæˆè¾“å…¥: [batch, seq_len, hidden] -> flatten to [M, H]"""
        # æ¨¡æ‹Ÿç»è¿‡ RMSNorm åçš„è¾“å…¥ (stdâ‰ˆ1.0)
        x = torch.randn(
            (batch_size, self.seq_len, self.H), 
            device=self.device, 
            dtype=torch.float32
        )
        x = x / (x.std() + 1e-6)  # æ ‡å‡†åŒ–
        return x.to(self.dtype)
    
    def _pytorch_native(self, x, gate_w, up_w, down_w):
        """PyTorch åŸç”Ÿå®ç° (3 ä¸ªç‹¬ç«‹ kernel)"""
        # x: [M, H]
        gate = F.linear(x, gate_w)      # [M, I]
        up = F.linear(x, up_w)          # [M, I]
        hidden = up * F.silu(gate.float()).half()  # [M, I]
        return F.linear(hidden, down_w)  # [M, H]
    
    def _benchmark_impl(self, func, x, gate_w, up_w, down_w, num_iter=50, warmup=10):
        """ç²¾ç¡®è®¡æ—¶"""
        # é¢„çƒ­
        for _ in range(warmup):
            _ = func(x, gate_w, up_w, down_w)
        torch.cuda.synchronize()
        
        # è®¡æ—¶
        start = torch.cuda.Event(enable_timing=True)
        end = torch.cuda.Event(enable_timing=True)
        
        start.record()
        for _ in range(num_iter):
            _ = func(x, gate_w, up_w, down_w)
        end.record()
        torch.cuda.synchronize()
        
        return start.elapsed_time(end) / num_iter  # ms
    
    def run(self, batch_sizes=[1, 2, 4, 8, 16, 32, 64, 128], num_iter=50):
        """è¿è¡Œå…¨é‡æµ‹è¯•"""
        results = []
        total_params = (self.I * self.H * 2 + self.H * self.I) / 1e6  # çº¦ 90M params
        
        print(f"\nğŸ“Š å¼€å§‹æµ‹è¯• (Params: ~{total_params:.1f}M)")
        print(f"{'Batch':<8} {'Seqs':<8} {'M':<10} {'PyTorch(ms)':<14} {'Optimized(ms)':<16} {'Speedup':<10} {'Status':<8}")
        print("-" * 80)
        
        gate_w, up_w, down_w = self._generate_weights()
        
        for batch in batch_sizes:
            M = batch * self.seq_len  # æ€» token æ•°
            
            try:
                # ç”Ÿæˆè¾“å…¥
                x = self._generate_input(batch)
                x_flat = x.view(-1, self.H)  # [M, H]
                
                # æ£€æŸ¥æ•°å€¼æ­£ç¡®æ€§ (ä»…ç¬¬ä¸€æ¬¡)
                if batch == batch_sizes[0]:
                    y_opt = fused_swiglu(x_flat, gate_w, up_w, down_w)
                    y_ref = self._pytorch_native(x_flat, gate_w, up_w, down_w)
                    max_err = torch.max(torch.abs(y_opt - y_ref)).item()
                    status = "âœ…" if max_err < 0.01 else "âŒ"
                else:
                    status = "-"
                
                # æ€§èƒ½æµ‹è¯•
                torch_time = self._benchmark_impl(
                    self._pytorch_native, x_flat, gate_w, up_w, down_w, num_iter
                )
                opt_time = self._benchmark_impl(
                    fused_swiglu, x_flat, gate_w, up_w, down_w, num_iter
                )
                
                speedup = torch_time / opt_time
                
                results.append({
                    'batch': batch,
                    'M': M,
                    'torch': torch_time,
                    'opt': opt_time,
                    'speedup': speedup,
                    'error': max_err if batch == batch_sizes[0] else 0
                })
                
                print(f"{batch:<8} {batch*self.seq_len:<8} {M:<10} {torch_time:<14.3f} {opt_time:<16.3f} {speedup:<10.2f}x {status:<8}")
                
                # æ˜¾å­˜æ¸…ç†
                del x, x_flat
                torch.cuda.empty_cache()
                
            except torch.cuda.OutOfMemoryError:
                print(f"{batch:<8} {batch*self.seq_len:<8} {M:<10} {'OOM':<14} {'OOM':<16} {'-':<10} {'âš ï¸':<8}")
                break
        
        return results
    
    def analyze(self, results):
        """æ·±åº¦åˆ†æ"""
        if not results:
            return
        
        print("\n" + "=" * 80)
        print("ğŸ“ˆ æ€§èƒ½åˆ†ææŠ¥å‘Š")
        print("=" * 80)
        
        # 1. åŠ é€Ÿæ¯”è¶‹åŠ¿
        print("\n1. åŠ é€Ÿæ¯”è¶‹åŠ¿:")
        for r in results:
            bar = "â–ˆ" * int(r['speedup'] * 10)
            print(f"   Batch={r['batch']:3d}: {r['speedup']:.2f}x {bar}")
        
        # 2. å¹³å‡åŠ é€Ÿ
        avg_speedup = sum(r['speedup'] for r in results) / len(results)
        max_speedup = max(r['speedup'] for r in results)
        min_speedup = min(r['speedup'] for r in results)
        
        print(f"\n2. ç»Ÿè®¡æ‘˜è¦:")
        print(f"   å¹³å‡åŠ é€Ÿ: {avg_speedup:.2f}x")
        print(f"   æœ€å¤§åŠ é€Ÿ: {max_speedup:.2f}x (Batch={[r for r in results if r['speedup']==max_speedup][0]['batch']})")
        print(f"   æœ€å°åŠ é€Ÿ: {min_speedup:.2f}x (Batch={[r for r in results if r['speedup']==min_speedup][0]['batch']})")
        
        # 3. æ˜¾å­˜èŠ‚çœåˆ†æ
        print(f"\n3. æ˜¾å­˜å ç”¨åˆ†æ (Batch={results[-1]['batch']}):")
        max_m = results[-1]['M']
        hidden_size = max_m * self.I * 2 / 1024**3  # GB
        print(f"   Hidden æ¿€æ´»æ˜¾å­˜: {hidden_size:.2f} GB (M={max_m}, I={self.I})")
        print(f"   è¯´æ˜: åˆ†ç¦»æ¶æ„éœ€é¢å¤–å­˜å‚¨ hiddenï¼Œä½†è®¡ç®—æ›´å¿«")
        
        # 4. ç«¯åˆ°ç«¯æ”¶ç›Šä¼°ç®—
        print(f"\n4. ç«¯åˆ°ç«¯æ”¶ç›Šä¼°ç®—:")
        mlp_ratio = 0.31  # MLP å  Transformer å±‚ 31%
        end2end_gain = (avg_speedup - 1) * mlp_ratio * 100
        print(f"   MLP å æ¯”: {mlp_ratio*100:.0f}%")
        print(f"   é¢„æœŸç«¯åˆ°ç«¯åŠ é€Ÿ: +{end2end_gain:.1f}%")
        print(f"   1000 tokens æ¨ç†: èŠ‚çœ ~{end2end_gain*0.1:.1f}ms (å‡è®¾åŸå»¶è¿Ÿ 100ms)")
        
        # 5. æœ€ä½³é…ç½®å»ºè®®
        best = max(results, key=lambda x: x['speedup'])
        print(f"\n5. æœ€ä½³é…ç½®:")
        print(f"   Batch Size: {best['batch']} (M={best['M']})")
        print(f"   åŠ é€Ÿæ¯”: {best['speedup']:.2f}x")
        print(f"   å»¶è¿Ÿ: {best['opt']:.2f}ms vs {best['torch']:.2f}ms")
        
        # 6. æ•°å€¼æ­£ç¡®æ€§
        if results[0]['error'] < 0.01:
            print(f"\nâœ… æ•°å€¼æ­£ç¡®æ€§: é€šè¿‡ (Max Error={results[0]['error']:.6f} < 0.01)")
        else:
            print(f"\nâŒ æ•°å€¼æ­£ç¡®æ€§: å¤±è´¥ (Max Error={results[0]['error']:.6f})")
        
        print("=" * 80)


def main():
    # è®¾ç½® GPU æ€§èƒ½æ¨¡å¼
    torch.backends.cudnn.benchmark = True
    
    benchmark = Qwen7BSwiGLUBenchmark()
    
    # æµ‹è¯•é…ç½® (ä»å•æ¡åˆ°æ»¡è´Ÿè½½)
    batch_sizes = [1, 2, 4, 8, 16, 32, 64, 128]
    
    results = benchmark.run(batch_sizes, num_iter=50)
    benchmark.analyze(results)
    
    # ä¿å­˜ç»“æœ
    try:
        import json
        with open('swiglu_qwen7b_results.json', 'w') as f:
            json.dump([{
                'batch': r['batch'],
                'M': r['M'],
                'pytorch_ms': r['torch'],
                'optimized_ms': r['opt'],
                'speedup': r['speedup']
            } for r in results], f, indent=2)
        print(f"\nğŸ’¾ ç»“æœå·²ä¿å­˜åˆ° swiglu_qwen7b_results.json")
    except Exception as e:
        pass
    
    print("\nğŸ‰ Qwen-7B SwiGLU åŸºå‡†æµ‹è¯•å®Œæˆ!")


if __name__ == "__main__":
    # æ£€æŸ¥ swiglu æ˜¯å¦å¯ç”¨
    try:
        from swiglu import fused_swiglu
    except ImportError as e:
        print(f"âŒ é”™è¯¯: æ— æ³•å¯¼å…¥ swiglu.py - {e}")
        print("   è¯·ç¡®ä¿ swiglu.py åœ¨åŒç›®å½•ä¸‹")
        sys.exit(1)
    
    main()
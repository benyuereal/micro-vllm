import torch
import time
import sys
import os

current_dir = os.path.dirname(os.path.abspath(__file__))
parent_dir = os.path.dirname(current_dir)
sys.path.insert(0, parent_dir)

from core.layer.std_mlp import MLP

try:
    import cpp_mlp
    HAS_CPP = True
    print("âœ… C++ Extension (cpp_mlp) loaded")
except ImportError as e:
    HAS_CPP = False
    print(f"âŒ Failed to load: {e}")
    exit(1)

def make_data(batch_size=1, num_heads=32, head_size=128, hidden_size=4096, intermediate_size=11008, device='cuda', dtype=torch.float16):
    """
    ç”Ÿæˆæµ‹è¯•æ•°æ® - ä½¿ç”¨ä¿å®ˆçš„å°å€¼åˆå§‹åŒ–é¿å… fp16 æº¢å‡º
    """
    # å…³é”®ï¼šä½¿ç”¨å°çš„éšæœºå€¼ï¼Œé¿å… fp16 æº¢å‡º
    # çœŸå®æ¨¡å‹æƒé‡é€šå¸¸æ˜¯æ­£æ€åˆ†å¸ƒ N(0, 0.02) çº§åˆ«
    
    return {
        'hidden': torch.randn(batch_size, 1, hidden_size, device=device, dtype=dtype) * 0.01,
        'attn_out': torch.randn(batch_size, num_heads, head_size, device=device, dtype=dtype) * 0.01,
        # æƒé‡ä½¿ç”¨ Xavier åˆå§‹åŒ–èŒƒå›´
        'attn_proj_weight': torch.randn(hidden_size, hidden_size, device=device, dtype=dtype) * 0.02,
        'norm_weight': torch.ones(hidden_size, device=device, dtype=dtype),  # RMSNorm weight é€šå¸¸æ˜¯ 1
        'gate_up_weight': torch.randn(hidden_size, 2*intermediate_size, device=device, dtype=dtype) * 0.02,
        'down_weight': torch.randn(intermediate_size, hidden_size, device=device, dtype=dtype) * 0.02,
        'eps': 1e-6
    }

def check_tensor(t, name):
    """æ£€æŸ¥å¼ é‡æ˜¯å¦åŒ…å« nan/inf"""
    has_nan = torch.isnan(t).any().item()
    has_inf = torch.isinf(t).any().item()
    if has_nan or has_inf:
        print(f"  âš ï¸  {name}: min={t.min():.2e}, max={t.max():.2e}, has_nan={has_nan}, has_inf={has_inf}")
        return False
    return True

def test_correct():
    """åŠŸèƒ½æµ‹è¯•"""
    print("\nğŸ§ª åŠŸèƒ½æµ‹è¯• (æ•°å€¼æ­£ç¡®æ€§)")
    print("-" * 50)
    
    # ä½¿ç”¨ä¿å®ˆåˆå§‹åŒ–
    d = make_data()
    
    # æ£€æŸ¥è¾“å…¥
    print("Checking inputs...")
    all_valid = True
    for k, v in d.items():
        if isinstance(v, torch.Tensor):
            all_valid &= check_tensor(v, k)
    if not all_valid:
        print("âŒ Input contains nan/inf, adjust initialization")
    
    # Python ç‰ˆæœ¬
    print("Running Python MLP...")
    try:
        py_out = MLP.forward(**d)
        check_tensor(py_out, "Python output")
    except Exception as e:
        print(f"âŒ Python error: {e}")
        return False
    
    # C++ ç‰ˆæœ¬
    print("Running C++ MLP...")
    try:
        cpp_out = cpp_mlp.forward(
            d['hidden'], d['attn_out'], 
            d['attn_proj_weight'], d['norm_weight'],
            d['gate_up_weight'], d['down_weight'], 
            d['eps']
        )
        check_tensor(cpp_out, "C++ output")
    except Exception as e:
        print(f"âŒ C++ error: {e}")
        return False
    
    # å¯¹æ¯”
    max_err = (py_out - cpp_out).abs().max().item()
    mean_err = (py_out - cpp_out).abs().mean().item()
    
    print(f"\nMax Error:  {max_err:.2e}")
    print(f"Mean Error: {mean_err:.2e}")
    
    # ç›¸å¯¹è¯¯å·®ï¼ˆæ›´åˆç†ï¼‰
    rel_err = ((py_out - cpp_out).abs() / (py_out.abs() + 1e-8)).max().item()
    print(f"Max Relative Error: {rel_err:.2e}")
    
    if max_err < 1e-2 or rel_err < 1e-2:  # fp16 å®¹å¿åº¦æ”¾å®½
        print("âœ… PASS")
        return True
    else:
        print("âŒ FAIL")
        print(f"Python: {py_out[0,0,:5]}")
        print(f"C++:    {cpp_out[0,0,:5]}")
        return False

def test_perf():
    """æ€§èƒ½æµ‹è¯•"""
    print("\nâš¡ æ€§èƒ½æµ‹è¯•")
    print("-" * 50)
    d = make_data()
    N = 1000
    
    # Warmup
    print("Warming up...")
    for _ in range(100):
        MLP.forward(**d)
        # ğŸ”¥ ä¿®å¤ï¼šè¡¥ä¸Š eps å‚æ•°
        cpp_mlp.forward(
            d['hidden'], d['attn_out'],
            d['attn_proj_weight'], d['norm_weight'],
            d['gate_up_weight'], d['down_weight'],
            d['eps']  # æ¼äº†è¿™ä¸ªï¼
        )
    torch.cuda.synchronize()
    
    # Python æµ‹è¯•
    t0 = time.time()
    for _ in range(N):
        MLP.forward(**d)
    torch.cuda.synchronize()
    py_t = (time.time() - t0) / N * 1000
    
    # C++ æµ‹è¯•
    t0 = time.time()
    for _ in range(N):
        # ğŸ”¥ ä¿®å¤ï¼šè¡¥ä¸Š eps å‚æ•°
        cpp_mlp.forward(
            d['hidden'], d['attn_out'],
            d['attn_proj_weight'], d['norm_weight'],
            d['gate_up_weight'], d['down_weight'],
            d['eps']  # æ¼äº†è¿™ä¸ªï¼
        )
    torch.cuda.synchronize()
    cpp_t = (time.time() - t0) / N * 1000
    
    print(f"Python (std_mlp): {py_t:.3f} ms")
    print(f"C++ (cpp_mlp):    {cpp_t:.3f} ms")
    print(f"Speedup:          {py_t/cpp_t:.2f}x")
    
    # 32 å±‚ä¼°ç®—
    print("\nğŸ“Š 32 å±‚æ•´ä½“ä¼°ç®—:")
    base = 10
    py_total = base + 32 * py_t
    cpp_total = base + 32 * cpp_t
    print(f"  Python: {py_total:.1f}ms/token ({1000/py_total:.1f} tokens/s)")
    print(f"  C++:    {cpp_total:.1f}ms/token ({1000/cpp_total:.1f} tokens/s)")

if __name__ == "__main__":
    if not torch.cuda.is_available():
        print("âŒ Need CUDA")
        exit(1)
    
    if test_correct():
        test_perf()
    else:
        print("\nåŠŸèƒ½æµ‹è¯•å¤±è´¥")
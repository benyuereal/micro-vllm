"""
===================================================================
QKV Forward - Qwen QKV ç¼–è¯‘ä¼˜åŒ–å®ç°
===================================================================

ğŸ“Œ **æ ¸å¿ƒåŠŸèƒ½**ï¼š
   - LayerNorm + QKV æŠ•å½±çš„ç¼–è¯‘èåˆ
   - ä¸“ä¸º Qwen æ¨¡å‹ä¼˜åŒ–

âš¡ **æ€§èƒ½ä¼˜åŒ–**ï¼š
   - torch.compile fullgraph æ¨¡å¼
   - ç®—å­èåˆå‡å°‘å†…å­˜è®¿é—®
   - é™æ€ shape ä¼˜åŒ–
"""
import torch
from kernel.rmsnorm import rms_norm


def compiled(num_heads: int, head_size: int, kv_num_heads: int):
    """
    ğŸ“Œ **ç¼–è¯‘ QKV Forward å‡½æ•°**
    
    ğŸ” **å‚æ•°**:
        - num_heads: æ³¨æ„åŠ›å¤´æ•°
        - head_size: æ¯ä¸ªå¤´çš„ç»´åº¦
        - kv_num_heads: KV å¤´æ•° (GQA æ”¯æŒ)
    
    âœ… **è¿”å›**:
        - ç¼–è¯‘åçš„ QKV forward å‡½æ•°
    """
    
    def qkv_forward(layer, hidden_states):
        """
        QKV å®ç° (ä¼šè¢« torch.compile ç¼–è¯‘)
        """
        residual = hidden_states
        
        # Qwen: LayerNorm + QKV èåˆæŠ•å½±
        hidden_states = rms_norm(hidden_states, layer.ln_1.weight, layer.ln_1.eps)
        qkv = layer.attn.c_attn(hidden_states)
        
        hidden_size = qkv.shape[-1] // 3
        q, k, v = qkv.split(hidden_size, dim=-1)
        
        batch_size, seq_len, _ = hidden_states.shape
        
        # Reshape: [B, S, D] -> [B, H, S, D]
        q = q.view(batch_size, num_heads, head_size).contiguous()
        k = k.view(batch_size, kv_num_heads, head_size).contiguous()
        v = v.view(batch_size, kv_num_heads, head_size).contiguous()
        
        return hidden_states, residual, q, k, v
    
    # ç¼–è¯‘å‡½æ•°
    return torch.compile(
        qkv_forward,
        mode="reduce-overhead",
        fullgraph=True,
        dynamic=False,
    )


class QKVForward:
    """
    ğŸ“Œ **QKV Forward å°è£…ç±»**
    """
    
    def __init__(self, num_heads: int, head_size: int, kv_num_heads: int):
        self.num_heads = num_heads
        self.head_size = head_size
        self.kv_num_heads = kv_num_heads
        self._forward = compiled(num_heads, head_size, kv_num_heads)
    
    def __call__(self, layer, hidden_states):
        """è°ƒç”¨ç¼–è¯‘åçš„ QKV"""
        return self._forward(layer, hidden_states)
